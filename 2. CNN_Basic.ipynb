{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN_Basic\n",
    "\n",
    "**References**\n",
    "+ http://bcho.tistory.com/1149\n",
    "\n",
    "## 1. Convolutional Network\n",
    "\n",
    "입력 데이터를 작은 크기의 필터들로 훑어가며 행렬곱 연산을 수행해 데이터의 특징을 추출(feature extraction)하는 방식이다. 일반적으로 Convolutional Layer는 '필터 + 활성함수'의 한 쌍으로 구성되며 이후 Pooling, Dropout 등을 포함 Fully Connected Layer를 거쳐 분류문제 등을 해결하는데 사용된다.\n",
    "\n",
    "### (1) Filter (Convolutional Layer)\n",
    "\n",
    "필터는 해당 데이터에 대해 필터가 가지고 있는 속성을 데이터가 가지고 있는지의 여부를 알아내기 위한 행렬이다. (곡선의 존재여부를 추출하는 필터 등..) 여러 종류의 필터를 한 데이터에 적용해 각 특징들의 유무를 판단할 수 있다면 그 특징에 해당하는 class로 classification을 하기 용이할 것이다. 보통 필터는 최초에 랜덤값으로 초기화되지만 학습을 통해 갱신되며 각각 특정한 특징을 대표하게 된다. 필터를 거친 데이터를 Feature Map이라고 한다.\n",
    "\n",
    "#### Stride\n",
    "\n",
    "스트라이드는 필터를 한 번에 몇 픽셀씩 옮길 것인가를 나타낸다. \n",
    "\n",
    "**strides = [1,2,2,1]** : 한 데이터를 가로세로 두칸씩 한 가지 색상으로 옮기겠다는 의미\n",
    "\n",
    "#### Padding\n",
    "\n",
    "보통 필터를 적용한 후의 이미지는 Convolution 연산에 의해 크기가 원본보다 작아진다. 특징이 충분히 추출되지 않았는데 이미지가 작아지면 특징 유실의 위험이 있으므로 주위 픽셀을 0값으로 메꿔주는 작업을 수행하는데 이것을 패딩이라고 한다.\n",
    "\n",
    "+ **padding = 'SAME'** : 패딩을 적용해 원본 사이즈를 유지\n",
    "+ **padding = 'VALID'** : 패딩을 적용하지 않고 그냥 냅둠\n",
    "\n",
    "### (2) Activation Function\n",
    "\n",
    "일반적인 신경망에서도 사용하는 활성함수로써 Sigmoid, ReLu 등이 있는데 요즘엔 대부분 ReLu를 사용한다. Sigmoid의 경우 신경망이 깊어질수록 전방의 가중치가 제대로 학습되지 않는 Gradient Vanishing 현상이 일어날 가능성이 커지기 때문이다. 아무튼 이 활성함수를 추출된 Feature Map에 적용해 (Relu의 경우) 0 이상의 값으로 해당 특징이 드러나는 정도를 표현해준다.\n",
    "\n",
    "### (3) Pooling Layer\n",
    "\n",
    "풀링은 Subsampling 즉 데이터의 차원을 축소하는 것이 그 목적이다. Conv Layer를 통해 특징추출이 어느정도 된 상태라면 데이터의 차원(크기)을 줄여 사용되는 특징의 수를 줄임으로서 **연산량을 낮출** 수 있고, 풀링 이후에도 유지되는 **강인한 특징들을 뽑아**낼 수 있으며, **Overfitting을 방지**할 수 있다는 많은 장점이 있다. \n",
    "\n",
    "모든 활성함수마다 적용할 필요는 없으며 특징을 어느정도 추출한 이후 선택적으로 적용한다.\n",
    "\n",
    "Conv Layer와 다르게 풀링 레이어는 레이어의 크기만큼 스트라이드를 취하기 때문에 **겹치는 픽셀이 없다.** 즉 Feature Map을 N등분 시킨다.\n",
    "\n",
    "가장 많이 쓰이는 풀링 방식은 활성함수를 거친 픽셀들 중 가장 큰 값을 취하는 Max-Pooling이다.\n",
    "\n",
    "### (4) Fully Connected Layer\n",
    "\n",
    "위의 긴 과정들을 거쳐 이미지마다 특징의 정도를 나타내는 최종 Feature Map이 완성된다. 이 Feature들을 기존에 사용하던 신경망에 넣고 Softmax 함수 등을 적용해 분류문제 등을 해결한다.\n",
    "\n",
    "### (5) Dropout\n",
    "\n",
    "신경망 사이의 연결을 랜덤하게 끊어 네트워크를 sparse하게 만듦으로써 Overfitting을 방지한다. Fully Connected Layer와 Softmax 사이에 넣기도 하고 Pooling Layer 뒤에 넣기도 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
